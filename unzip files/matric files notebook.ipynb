{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6eeaee9d-4ceb-4885-83ee-6bc675b6bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile \n",
    "import json\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a41e9a7-8fda-4607-bd75-1c40607a11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = {\n",
    "    \"Mathematics\": \"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-Mathematics.zip\",\n",
    "    \"Physical Sciences\": \"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-Physical-Sciences.zip\",\n",
    "    \"Accounting\": \"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-Accounting.zip\",\n",
    "    \"English\": \"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-English.zip\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "632f8f39-5b45-41cf-a9c9-50fe970dff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-Mathematics.zip\", stream =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3dc7b358-9d15-4a1c-9753-0b4dc7f95807",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://s3.af-south-1.amazonaws.com/www.teachme2.com/matric-past-papers/2018-2023-Mathematics.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de0a24a2-fb12-4da5-abb2-dfa552c4b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = \"2018-2023-Mathematics.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8df3854f-8f7c-45eb-b604-1dac539cb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function get's the files from \n",
    "def get_files(url, subject,path=\".\"):\n",
    "    file =f\"{subject}.zip\"\n",
    "\n",
    "\n",
    "    file_path=os.path.join(path,file)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        response = requests.get(url,stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):  # Corrected here\n",
    "                f.write(chunk)\n",
    "                \n",
    "        return print(f\"sucessfuly downloaded and stored {subject}.zip file\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error observed while processing file {url}:{e}\")\n",
    "        return None\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07d75c03-863d-4487-a4c4-ffafd109ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucessfuly downloaded and stored Mathematics.zip file\n",
      "sucessfuly downloaded and stored Physical Sciences.zip file\n",
      "sucessfuly downloaded and stored Accounting.zip file\n",
      "sucessfuly downloaded and stored English.zip file\n"
     ]
    }
   ],
   "source": [
    "#Download zip files\n",
    "folder_path = \".\"\n",
    "\n",
    "for subject, url in links.items():\n",
    "    file_path = get_files(url, subject, path=folder_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fbedff2a-69fc-42cd-bf8a-0e5ffa92da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this finction extract zip files\n",
    "def extract_files(files):\n",
    "        \n",
    "    for file in files:\n",
    "        zip_file =f\"{file}.zip\"\n",
    "        print(zip_file)\n",
    "        # loading the temp.zip and creating a zip object \n",
    "        with ZipFile(zip_file, 'r') as zObject: \n",
    "        \n",
    "        \t# Extracting all the members of the zip \n",
    "        \t# into a specific location. \n",
    "        \tzObject.extractall(path=f\"./extracts/{file}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc9d8b6c-07a1-422b-ae14-39ac6ca35f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics.zip\n",
      "Physical Sciences.zip\n",
      "Accounting.zip\n",
      "English.zip\n"
     ]
    }
   ],
   "source": [
    "# extract zip files\n",
    "\n",
    "files =[\"Mathematics\",\"Physical Sciences\", \"Accounting\",\"English\"]\n",
    "extract_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d415b1cd-4889-4c65-9bfa-ad9962640620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_questions(pdf_path):\n",
    "    # Initialize a dictionary to store questions and answers\n",
    "    questions_dict = {}\n",
    "\n",
    "    # Read the PDF file\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            text += page_text if page_text else f\"Page {page_num + 1} has no text extracted.\\n\"\n",
    "    \n",
    "    # Define regex patterns for question numbers and sub-question numbers\n",
    "    question_pattern = r\"(\\d+\\.\\d+(\\.\\d+)?)\\s*([A-Za-z0-9'\\\".,;/\\s\\-]+)\"\n",
    "    sub_question_pattern = r\"(\\d+\\.\\d+\\.\\d+)\\s*\\.?\\s*(.*)\"\n",
    "\n",
    "    # Split text into lines and process each line\n",
    "    lines = text.splitlines()\n",
    "    current_question = None\n",
    "    current_sub_question = None\n",
    "\n",
    "    for line in lines:\n",
    "        # Check for main question or sub-question\n",
    "        question_match = re.match(question_pattern, line)\n",
    "        sub_question_match = re.match(sub_question_pattern, line)\n",
    "\n",
    "        if question_match:\n",
    "            # Capture the main question\n",
    "            question_number = question_match.group(1)\n",
    "            question_content = question_match.group(3).strip()\n",
    "\n",
    "            # Start a new section in the dictionary\n",
    "            current_question = question_number\n",
    "            questions_dict[current_question] = {\"content\": question_content, \"sub_questions\": {}}\n",
    "\n",
    "        elif sub_question_match:\n",
    "            # Capture sub-question content\n",
    "            sub_question_number = sub_question_match.group(1)\n",
    "            sub_question_content = sub_question_match.group(2).strip()\n",
    "\n",
    "            if current_question:\n",
    "                # Add the sub-question to the appropriate question in the dictionary\n",
    "                questions_dict[current_question][\"sub_questions\"][sub_question_number] = {\n",
    "                    \"content\": sub_question_content\n",
    "                }\n",
    "\n",
    "    return questions_dict\n",
    "\n",
    "def save_to_json(data, json_output_path):\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "20655280-edc2-40e4-a59c-ef069979638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extracted and saved to output_file.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_questions(pdf_path):\n",
    "    # Initialize a dictionary to store questions and answers\n",
    "    questions_dict = {}\n",
    "\n",
    "    # Read the PDF file\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            text += page_text if page_text else f\"Page {page_num + 1} has no text extracted.\\n\"\n",
    "    \n",
    "    # Define regex patterns for question numbers and sub-question numbers\n",
    "    question_pattern = r\"(\\d+\\.\\d+(\\.\\d+)?)\\s*([A-Za-z0-9'\\\".,;/\\s\\-]+)\"\n",
    "    sub_question_pattern = r\"(\\d+\\.\\d+\\.\\d+)\\s*\\.?\\s*(.*)\"\n",
    "    answer_pattern = r\"([A-Za-z0-9'\\-\\s\\.,:;]+)\\n*(\\d+[\\.,\\d]+)\"  # Captures figures or additional details\n",
    "\n",
    "    # Split text into lines and process each line\n",
    "    lines = text.splitlines()\n",
    "    current_question = None\n",
    "    current_sub_question = None\n",
    "    answer = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        # Check for main question or sub-question\n",
    "        question_match = re.match(question_pattern, line)\n",
    "        sub_question_match = re.match(sub_question_pattern, line)\n",
    "        answer_match = re.match(answer_pattern, line)\n",
    "\n",
    "        if question_match:\n",
    "            # Capture the main question\n",
    "            question_number = question_match.group(1)\n",
    "            question_content = question_match.group(3).strip()\n",
    "\n",
    "            # Start a new section in the dictionary\n",
    "            current_question = question_number\n",
    "            questions_dict[current_question] = {\"content\": question_content, \"sub_questions\": {}}\n",
    "            answer = \"\"  # Reset answer after every new main question\n",
    "\n",
    "        elif sub_question_match:\n",
    "            # Capture sub-question content\n",
    "            sub_question_number = sub_question_match.group(1)\n",
    "            sub_question_content = sub_question_match.group(2).strip()\n",
    "\n",
    "            if current_question:\n",
    "                # Add the sub-question to the appropriate question in the dictionary\n",
    "                if current_question not in questions_dict:\n",
    "                    questions_dict[current_question] = {\"content\": \"\", \"sub_questions\": {}}\n",
    "                \n",
    "                questions_dict[current_question][\"sub_questions\"][sub_question_number] = {\n",
    "                    \"content\": sub_question_content,\n",
    "                    \"answer\": \"\"  # Placeholder for answer content\n",
    "                }\n",
    "\n",
    "        elif answer_match:\n",
    "            # Capture additional details or answers after the question\n",
    "            answer_content = answer_match.group(1).strip()\n",
    "            figures = answer_match.group(2).strip()\n",
    "\n",
    "            if current_question:\n",
    "                # Add the answer content to the current sub-question\n",
    "                if current_sub_question:\n",
    "                    questions_dict[current_question][\"sub_questions\"][current_sub_question][\"answer\"] = {\n",
    "                        \"content\": answer_content,\n",
    "                        \"figures\": figures\n",
    "                    }\n",
    "                else:\n",
    "                    questions_dict[current_question][\"answer\"] = {\n",
    "                        \"content\": answer_content,\n",
    "                        \"figures\": figures\n",
    "                    }\n",
    "    \n",
    "    return questions_dict\n",
    "\n",
    "def save_to_json(data, json_output_path):\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage with your file paths\n",
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "json_output_path = 'output_file.json'\n",
    "\n",
    "# Extract questions from the PDF and save to JSON\n",
    "questions_data = extract_questions(pdf_path)\n",
    "save_to_json(questions_data, json_output_path)\n",
    "\n",
    "print(f\"Questions extracted and saved to {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c2f9238-ee0d-4138-a23f-534f2e3acf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extracted and saved to output_file.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your file paths\n",
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Paper-1-Answer-Book-English.pdf'\n",
    "json_output_path = 'output_file.json'\n",
    "\n",
    "\n",
    "# Extract questions from the PDF and save to JSON\n",
    "questions_data = extract_questions(pdf_path)\n",
    "save_to_json(questions_data, json_output_path)\n",
    "\n",
    "print(f\"Questions extracted and saved to {json_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a3d871f-4504-45c3-a798-f171283e3b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extracted and saved to output_file.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your file paths\n",
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Paper-1-Answer-Book-English.pdf'\n",
    "json_output_path = 'output_file.json'\n",
    "\n",
    "# Extract questions from the PDF and save to JSON\n",
    "questions_data = extract_questions(pdf_path)\n",
    "save_to_json(questions_data, json_output_path)\n",
    "\n",
    "print(f\"Questions extracted and saved to {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b5f68795-c788-41d3-b9f8-68fc17c9d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extracted and saved to output_file.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_questions(pdf_path):\n",
    "    # Initialize a dictionary to store questions and answers\n",
    "    questions_dict = {}\n",
    "\n",
    "    # Read the PDF file\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            text += page_text if page_text else f\"Page {page_num + 1} has no text extracted.\\n\"\n",
    "    \n",
    "    # Define regex patterns for question numbers and sub-question numbers\n",
    "    question_pattern = r\"(\\d+\\.\\d+(\\.\\d+)?)\\s*([A-Za-z0-9'\\\".,;/\\s\\-]+)\"\n",
    "    sub_question_pattern = r\"(\\d+\\.\\d+\\.\\d+)\\s*\\.?\\s*(.*)\"\n",
    "    \n",
    "    # Split text into lines and process each line\n",
    "    lines = text.splitlines()\n",
    "    current_question = None\n",
    "    current_sub_question = None\n",
    "    current_sub_question_content = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check for main question or sub-question\n",
    "        question_match = re.match(question_pattern, line)\n",
    "        sub_question_match = re.match(sub_question_pattern, line)\n",
    "\n",
    "        if question_match:\n",
    "            # Capture the main question\n",
    "            question_number = question_match.group(1)\n",
    "            question_content = question_match.group(3).strip()\n",
    "\n",
    "            # Start a new section in the dictionary\n",
    "            current_question = question_number\n",
    "            questions_dict[current_question] = {\"content\": question_content, \"sub_questions\": {}}\n",
    "            current_sub_question_content = \"\"  # Reset content after every new main question\n",
    "\n",
    "        elif sub_question_match:\n",
    "            # Capture sub-question content (level 3: 1.1.1, 1.1.2 etc.)\n",
    "            sub_question_number = sub_question_match.group(1)\n",
    "            sub_question_content = sub_question_match.group(2).strip()\n",
    "\n",
    "            if current_question:\n",
    "                # Add the sub-question to the appropriate question in the dictionary\n",
    "                if current_question not in questions_dict:\n",
    "                    questions_dict[current_question] = {\"content\": \"\", \"sub_questions\": {}}\n",
    "                \n",
    "                # Start a new entry for sub-question (store it under sub-question number)\n",
    "                questions_dict[current_question][\"sub_questions\"][sub_question_number] = {\n",
    "                    \"content\": sub_question_content,\n",
    "                    \"details\": \"\"  # Placeholder for any additional details, multiple-choice options, or further elaborations\n",
    "                }\n",
    "                current_sub_question = sub_question_number  # Track the current sub-question\n",
    "\n",
    "        elif current_sub_question:\n",
    "            # Handle multi-line answers or tables (append any continuation of the sub-question content)\n",
    "            current_sub_question_content += line.strip() + \"\\n\"  # Append the content to the details section\n",
    "            \n",
    "            # Once a line with a new question is detected, store the details\n",
    "            if re.match(question_pattern, line):  # Detected a new main question (end of current details)\n",
    "                if current_sub_question:\n",
    "                    # Store the content under the current sub-question\n",
    "                    questions_dict[current_question][\"sub_questions\"][current_sub_question][\"details\"] = current_sub_question_content.strip()\n",
    "                current_sub_question_content = \"\"  # Reset details after storing it\n",
    "                \n",
    "            # Check if it’s the end of the document (if no new questions or sub-questions are detected)\n",
    "            if line.strip() == \"\" and current_sub_question_content:\n",
    "                # Store the final content for the current sub-question\n",
    "                questions_dict[current_question][\"sub_questions\"][current_sub_question][\"details\"] = current_sub_question_content.strip()\n",
    "\n",
    "    # Final step: Store remaining details if any sub-question content was pending\n",
    "    if current_sub_question_content:\n",
    "        questions_dict[current_question][\"sub_questions\"][current_sub_question][\"details\"] = current_sub_question_content.strip()\n",
    "    \n",
    "    return questions_dict\n",
    "\n",
    "def save_to_json(data, json_output_path):\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage with your file paths\n",
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "json_output_path = 'output_file.json'\n",
    "\n",
    "# Extract questions from the PDF and save to JSON\n",
    "questions_data = extract_questions(pdf_path)\n",
    "save_to_json(questions_data, json_output_path)\n",
    "\n",
    "print(f\"Questions extracted and saved to {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f56f0078-1cdd-42ab-a14d-efea33be8bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete! JSON saved to: output_file.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def pdf_to_json(pdf_path, json_output_path):\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        with open(pdf_path, \"rb\") as pdf_file:\n",
    "            pdf = PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            \n",
    "            # Extract text from each page of the PDF\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                page_text = page.extract_text()\n",
    "                text += page_text if page_text else f\"Page {page_num + 1} has no text extracted.\\n\"\n",
    "\n",
    "        # Create a dictionary to store the extracted content\n",
    "        text_object = {\n",
    "            \"content\": text,\n",
    "            \"original_pdf_path\": pdf_path\n",
    "        }\n",
    "\n",
    "        # Write the extracted text to a JSON file\n",
    "        with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(text_object, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Extraction complete! JSON saved to: {json_output_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "\n",
    "# Example usage\n",
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "json_output_path = 'output_file.json'\n",
    "pdf_to_json(pdf_path, json_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b813a20-63fc-4cd0-a6f0-27cac0672b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_pdf_with_pymupdf(file_path):\n",
    "    # Read the PDF and extract text\n",
    "    document_text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            document_text += page.get_text()\n",
    "\n",
    "    # Split the text into lines for processing\n",
    "    lines = document_text.split(\"\\n\")\n",
    "    \n",
    "    # Initialize variables\n",
    "    json_structure = {}\n",
    "    current_hierarchy = []\n",
    "    current_content = []\n",
    "\n",
    "    def set_nested_value(dictionary, keys, value):\n",
    "        \"\"\"Helper function to set a value in a nested dictionary.\"\"\"\n",
    "        for key in keys[:-1]:\n",
    "            # Ensure each level is a dictionary\n",
    "            dictionary = dictionary.setdefault(key, {})\n",
    "        last_key = keys[-1]\n",
    "        if last_key in dictionary:\n",
    "            # Append to existing content if key exists\n",
    "            if isinstance(dictionary[last_key], dict):\n",
    "                raise ValueError(\"Expected a string but found a dictionary for the same level!\")\n",
    "            dictionary[last_key] += f\"\\n{value}\"\n",
    "        else:\n",
    "            # Create new key with value\n",
    "            dictionary[last_key] = value\n",
    "\n",
    "    # Regex patterns for detecting levels (e.g., 1., 1.1, 1.1.1)\n",
    "    level_pattern = re.compile(r'^(\\d+(\\.\\d+)*)(?!\\S)')\n",
    "\n",
    "    for line in lines:\n",
    "        match = level_pattern.match(line.strip())\n",
    "        if match:\n",
    "            # If a level is found, finalize the current content\n",
    "            if current_hierarchy:\n",
    "                set_nested_value(json_structure, current_hierarchy, \"\\n\".join(current_content).strip())\n",
    "\n",
    "            # Update the current hierarchy and reset content\n",
    "            level = match.group(1).split(\".\")\n",
    "            current_hierarchy = level\n",
    "            current_content = [line.strip()]\n",
    "        else:\n",
    "            # Add line to current content if no new level is found\n",
    "            current_content.append(line.strip())\n",
    "\n",
    "    # Add the last collected content to the JSON structure\n",
    "    if current_hierarchy:\n",
    "        set_nested_value(json_structure, current_hierarchy, \"\\n\".join(current_content).strip())\n",
    "\n",
    "    return json_structure\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace this with your PDF file path\n",
    "    pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "    try:\n",
    "        parsed_json = parse_pdf_with_pymupdf(pdf_path)\n",
    "\n",
    "        # Save JSON to a file\n",
    "        output_file = \"parsed_document.json\"\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(parsed_json, f, indent=4)\n",
    "\n",
    "        print(f\"Parsed JSON has been saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4aa9ba0e-1ccf-42bd-8a42-841f53a32d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "json_output_path = 'output_file.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "89a34e56-000b-4d18-ba8d-68864d2758ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4289cac-3f93-45cd-8e7e-b60f274f4888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "95271d84-63b6-4cde-8623-569507fdcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed JSON has been saved to parsed_document.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_pdf_with_pymupdf(file_path):\n",
    "    # Read the PDF and extract text\n",
    "    document_text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            document_text += page.get_text()\n",
    "\n",
    "    # Split the text into lines for processing\n",
    "    lines = document_text.split(\"\\n\")\n",
    "    \n",
    "    # Initialize variables\n",
    "    json_structure = {}\n",
    "    current_hierarchy = []\n",
    "    current_content = []\n",
    "\n",
    "    def set_nested_value(dictionary, keys, value):\n",
    "        \"\"\"Helper function to set a value in a nested dictionary.\"\"\"\n",
    "        for key in keys[:-1]:\n",
    "            # Ensure the structure is a dictionary\n",
    "            if key not in dictionary or not isinstance(dictionary[key], dict):\n",
    "                dictionary[key] = {}\n",
    "            dictionary = dictionary[key]\n",
    "        \n",
    "        last_key = keys[-1]\n",
    "        if last_key in dictionary:\n",
    "            # If the key exists, decide how to handle it\n",
    "            if isinstance(dictionary[last_key], dict):\n",
    "                # Add content under a \"content\" key\n",
    "                if \"content\" in dictionary[last_key]:\n",
    "                    dictionary[last_key][\"content\"] += f\"\\n{value}\"\n",
    "                else:\n",
    "                    dictionary[last_key][\"content\"] = value\n",
    "            elif isinstance(dictionary[last_key], str):\n",
    "                # Convert existing string to a dictionary with \"content\"\n",
    "                dictionary[last_key] = {\"content\": dictionary[last_key] + f\"\\n{value}\"}\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected type for {last_key}: {type(dictionary[last_key])}\")\n",
    "        else:\n",
    "            # Assign new value\n",
    "            dictionary[last_key] = value\n",
    "\n",
    "    # Regex patterns for detecting levels (e.g., 1., 1.1, 1.1.1)\n",
    "    level_pattern = re.compile(r'^(\\d+(\\.\\d+)*)(?!\\S)')\n",
    "\n",
    "    for line in lines:\n",
    "        match = level_pattern.match(line.strip())\n",
    "        if match:\n",
    "            # If a level is found, finalize the current content\n",
    "            if current_hierarchy:\n",
    "                set_nested_value(json_structure, current_hierarchy, \"\\n\".join(current_content).strip())\n",
    "\n",
    "            # Update the current hierarchy and reset content\n",
    "            level = match.group(1).split(\".\")\n",
    "            current_hierarchy = level\n",
    "            current_content = [line.strip()]\n",
    "        else:\n",
    "            # Add line to current content if no new level is found\n",
    "            current_content.append(line.strip())\n",
    "\n",
    "    # Add the last collected content to the JSON structure\n",
    "    if current_hierarchy:\n",
    "        set_nested_value(json_structure, current_hierarchy, \"\\n\".join(current_content).strip())\n",
    "\n",
    "    return json_structure\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace this with your PDF file path\n",
    "    pdf_path = './extracts/Accounting/2018-Feb-March-Accounting-Memo-1-English.pdf'\n",
    "    try:\n",
    "        parsed_json = parse_pdf_with_pymupdf(pdf_path)\n",
    "\n",
    "        # Save JSON to a file\n",
    "        output_file = \"parsed_document.json\"\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(parsed_json, f, indent=4)\n",
    "\n",
    "        print(f\"Parsed JSON has been saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f113f-568e-4ba1-aa9a-89384f7dfc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
